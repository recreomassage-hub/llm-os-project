# üìò PRD 2.1 ‚Äî Flow Logic (MediaPipe Assessment + Plans)

*(Production-ready style: CI/CD + Rollback + Env + Migrations + Security + Monitoring, based on PRD‚Äë7.1 structure)*

**–í–µ—Ä—Å–∏—è:** 2.1  
**–î–∞—Ç–∞:** 2025-12-18  
**–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞:** `docs/PRD-7.1-Enterprise-Fitness-Assessment-Platform.md` (–∫–∞–∫ —ç—Ç–∞–ª–æ–Ω —Å—Ç—Ä—É–∫—Ç—É—Ä—ã) + —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ —Ç–∞—Ä–∏—Ñ–∞–º Flow Logic (Free/Basic/Pro/Pro+)  
**MVP language:** **English only** (UI, emails, system messages)

---

# 1. EXECUTIVE SUMMARY

## 1.1. Product Overview

**Flow Logic** ‚Äî B2C –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–≤–∏–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ **MediaPipe pose estimation** –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ **AI‚Äë–ø–ª–∞–Ω**, **—É–º–Ω—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å**, **–≥—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (charts)** –∏ **–Ω–∞–±–æ—Ä retention‚Äë—É–ª—É—á—à–µ–Ω–∏–π** (tier‚Äëgated).

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- –ù–µ —è–≤–ª—è–µ—Ç—Å—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º –ø—Ä–æ–¥—É–∫—Ç–æ–º (wellness only)
- 4 —Ç–∞—Ä–∏—Ñ–∞ **Free / Basic / Pro / Pro+**
- –ß—ë—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–µ—Å—Ç–æ–≤ (MediaPipe) –∏ –Ω–∞–ª–∏—á–∏—é —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫
- Production-grade CI/CD —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ rollback

## 1.2. Business Value

- **–ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –∏ problem areas —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–æ–≤
- **–ú–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Ü–µ–Ω–Ω–æ—Å—Ç—å:** **Free –±–µ–∑ –ø–ª–∞–Ω–∞**, **Basic+ —Å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è–º–∏/–ø–ª–∞–Ω–æ–º**
- **Retention –¥—Ä–∞–π–≤–µ—Ä:** –ø–ª–∞–Ω + —Ç—Ä–µ–∫–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–≤ —Ä–∞–º–∫–∞—Ö paid tiers)

## 1.3. Technical Foundation

- **Frontend:** React (Vercel)
- **Backend:** AWS Lambda + API Gateway
- **Auth:** AWS Cognito
- **DB:** DynamoDB (KMS encryption)
- **Storage/CDN:** S3 + CloudFront
- **Messaging:** EventBridge + SQS FIFO (–¥–ª—è —Ç—è–∂—ë–ª—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤/—Ä–µ—Ç—Ä–∞–µ–≤)
- **Monitoring:** Sentry + CloudWatch (+ X-Ray –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- **CI/CD:** GitHub Actions + Vercel + Serverless Framework

---

# 2. PRODUCT SCOPE

## 2.1. Target Users

- B2C –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ 18‚Äì65
- –û—Ñ–∏—Å–Ω—ã–µ —Ä–∞–±–æ—Ç–Ω–∏–∫–∏ (—à–µ—è/—Å–ø–∏–Ω–∞), —Ñ–∏—Ç–Ω–µ—Å‚Äë–ª—é–±–∏—Ç–µ–ª–∏ (–ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞ —Ç—Ä–∞–≤–º)

## 2.2. Key User Goals

- –ü—Ä–æ–π—Ç–∏ —Ç–µ—Å—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ –¥–≤–∏–∂–µ–Ω–∏—è
- –ü–æ–ª—É—á–∏—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–æ—Ü–µ–Ω–∫–∞ + problem areas)
- –î–ª—è **Basic+**: –ø–æ–ª—É—á–∏—Ç—å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –∏ –ø–ª–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º

## 2.3. Non-Goals

- –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π / medical claims
- –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∑–∞–∫–ª—é—á–µ–Ω–∏—è
- Live coaching / –≤–∏–¥–µ–æ‚Äë–∑–≤–æ–Ω–∫–∏
- –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å –≤ MVP (–≤ MVP —Ç–æ–ª—å–∫–æ English)

---

# 3. BUSINESS REQUIREMENTS

## 3.1. Core Features

1. **Onboarding**: —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è/–ª–æ–≥–∏–Ω (email/password), consent + wellness disclaimer
2. **Tier selection**: Free / Basic / Pro / Pro+
3. **MediaPipe assessment**: 3/3/7/15 —Ç–µ—Å—Ç–æ–≤
4. **Results**: score + problem areas (–≤—Å–µ tiers)
5. **Exercises + training plan**: —Ç–æ–ª—å–∫–æ **Basic+** (–Ω–∞ –æ—Å–Ω–æ–≤–µ 3/7/15 —Ç–µ—Å—Ç–æ–≤)
6. **Billing & subscriptions**: Stripe
7. **Account lifecycle**: –æ—Ç–º–µ–Ω–∞ –ø–æ–¥–ø–∏—Å–∫–∏, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ paid —Ñ–∏—á –ø—Ä–∏ –∏—Å—Ç–µ—á–µ–Ω–∏–∏
8. **Observability**: monitoring/alerts/releases
9. **AI Plan Generator** (Basic+) ‚Äî –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –∏ –ø–ª–∞–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Ç–µ—Å—Ç–æ–≤ (3/7/15)
10. **Smart Calendar** (Basic+) ‚Äî 2‚Äì4 –∑–∞–¥–∞—á–∏ –≤ –¥–µ–Ω—å, —á–µ–∫-–ª–∏—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, streak
11. **Charts / Progress Dashboard** (Basic+) ‚Äî –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (streak, completion, improvements)
12. **Retention Improvements** (Pro+) ‚Äî –º–∏–∫—Ä–æ-—Ä–µ—Ñ–ª–µ–∫—Å–∏—è, –º–∏–∫—Ä–æ-–∫–æ—É—á–∏–Ω–≥, –±–µ–π–¥–∂–∏/–ø–æ—Ä–æ–≥–∏, –∞–≤—Ç–æ-–∞–¥–∞–ø—Ç–∞—Ü–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏, share card

## 3.2. KPIs

- Activation Rate: > 65%
- Test completion rate: > 75%
- Time to results: —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤
- Deploy Time: < 4 –º–∏–Ω—É—Ç—ã
- Rollback Time: < 1 –º–∏–Ω—É—Ç–∞

## 3.3. Cost Optimization Targets

- MVP (0‚Äì100 users): ‚â§ $50/–º–µ—Å
- Early Stage (100‚Äì1000 users): ‚â§ $100/–º–µ—Å
- Growth (1000‚Äì5000 users): ‚â§ $320/–º–µ—Å


---

## 3.4. (–ò–ò + –ö–∞–ª–µ–Ω–¥–∞—Ä—å + Charts + –£–ª—É—á—à–µ–Ω–∏—è) ‚Äî —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞

> –í–∞–∂–Ω–æ: –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫/–ø–ª–∞–Ω–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å **Basic**. Free –æ—Å—Ç–∞—ë—Ç—Å—è **—Ç–æ–ª—å–∫–æ —Ç–µ—Å—Ç—ã + —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**.

### 3.4.1. AI Plan Generator (Basic+)

- **Input:** —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤ (tier: 3/7/15), problem areas, –±–∞–∑–æ–≤—ã–µ preferences (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- **Output:**
  - —Å–ø–∏—Å–æ–∫ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π (exercise list)
  - –±–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ (Basic ‚Äî lite) / —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π (Pro/Pro+)

**Tier logic:**
- **Basic:** –ø–ª–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ **3 —Ç–µ—Å—Ç–æ–≤** (lite)
- **Pro:** –ø–ª–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ **7 —Ç–µ—Å—Ç–æ–≤**
- **Pro+:** –ø–ª–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ **15 —Ç–µ—Å—Ç–æ–≤** + –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞

### 3.4.2. Smart Calendar (Basic+)

- –°–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –ø–æ –ø–ª–∞–Ω—É:
  - **2‚Äì4 –∑–∞–¥–∞—á–∏ –≤ –¥–µ–Ω—å**
  - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã: must/should (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
  - –æ—Ç–º–µ—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á (checkbox)

**Streak rules (MVP):**
- 100% –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞ –¥–µ–Ω—å ‚Üí +2
- 70‚Äì99% ‚Üí +1
- <70% ‚Üí +0

### 3.4.3. Charts / Progress Dashboard (Basic+)

–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –≥—Ä–∞—Ñ–∏–∫–æ–≤:
- streak (line)
- completion (bar)
- test improvements (trend –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ç–µ—Å—Ç–∞–º)

**Performance target:** chart/dashboard load < 3s (mobile).

### 3.4.4. –£–ª—É—á—à–µ–Ω–∏—è (Retention Improvements) (Pro+)

- –º–∏–∫—Ä–æ-—Ä–µ—Ñ–ª–µ–∫—Å–∏—è (–ø–æ—Å–ª–µ —Å–µ—Å—Å–∏–∏): self-report (–Ω–∞–ø—Ä–∏–º–µ—Ä 0‚Äì10)
- –º–∏–∫—Ä–æ-–∫–æ—É—á–∏–Ω–≥ (insights –ø–æ–¥ –¥–∞—à–±–æ—Ä–¥–æ–º)
- –±–µ–π–¥–∂–∏/–ø–æ—Ä–æ–≥–∏
- –∞–≤—Ç–æ-–∞–¥–∞–ø—Ç–∞—Ü–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä —Å–Ω–∏–∂–µ–Ω–∏–µ –æ–±—ä—ë–º–∞ –ø—Ä–∏ —Å–µ—Ä–∏–∏ ¬´–∫—Ä–∞—Å–Ω—ã—Ö¬ª –¥–Ω–µ–π)
- share card –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

---

# 4. PRODUCT SCOPE & TIERS (UPDATED WITH BASIC)

## 4.1. Pricing Matrix (Mandatory)

| Tier | –¢–µ—Å—Ç–æ–≤ (MediaPipe) | –ß—Ç–æ –ø–æ–ª—É—á–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å | CPU | Pose Accuracy | –¶–µ–Ω–∞ | Lambda |
|---|---:|---|---:|---:|---:|---|
| **Free** | 3 | –¢–æ–ª—å–∫–æ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ 3 —Ç–µ—Å—Ç–æ–≤ –∏ —ç–∫—Ä–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ—Ü–µ–Ω–∫–∞ –∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∑–æ–Ω—ã), **–±–µ–∑ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –∏ –ø–ª–∞–Ω–∞** | 20% | 94‚Äì96% | $0 | 512MB, 15s |
| **Basic** | 3 | –¢–æ –∂–µ, —á—Ç–æ Free, –ø–ª—é—Å: **–ø–æ–¥–±–æ—Ä —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π** –∏ **–±–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏** –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º 3 —Ç–µ—Å—Ç–æ–≤ | 25‚Äì30% | 94‚Äì96% | $4.99 | 512MB, 15‚Äì20s |
| **Pro** | 7 | 7 —Ç–µ—Å—Ç–æ–≤ —Å MediaPipe, —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á—ë—Ç + **—É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –∏ –ø–ª–∞–Ω** (–∫–∞–∫ —É Basic, –Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ 7 —Ç–µ—Å—Ç–æ–≤) | 45% | 92‚Äì94% | $9.99 | 768MB, 20s |
| **Pro+** | 15 | 15 —Ç–µ—Å—Ç–æ–≤ —Å MediaPipe, –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç + **—É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –∏ –ø–ª–∞–Ω** (–∫–∞–∫ —É Pro, –Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ 15 —Ç–µ—Å—Ç–æ–≤) | 100% | 91‚Äì93% | $19.99 | 1024MB ARM64, 30s |

## 4.2. Tier gating rules (Mandatory)
- **Monthly tests cap (all tiers, must):** a user can complete at most the plan‚Äôs number of **distinct tests per calendar month** (Free=3, Basic=3, Pro=7, Pro+=15), unless explicitly stated otherwise in this PRD.
- **Attempts cap (must):** each test has up to **3 video attempts per day** (re-records/submissions) to pass MediaPipe quality gates.
- **3‚Äëtests plan math (must):** if a plan has **3 tests/month**, then the daily attempt ceiling is **9 attempts/day** (3 tests √ó 3 attempts).




- **MediaPipe-only (all tiers):** any test available in **Free/Basic/Pro/Pro+** must be **executed and scored via MediaPipe**. Tier only changes **how many tests** are available.
- **No fallback scoring (all tiers):** if MediaPipe quality gates fail, the test is **not completed** (user must retry); **no manual scoring** and **no non‚ÄëMediaPipe scoring**. After max retries, an optional questionnaire may be offered for **generic guidance only**, but it **does not count as completing the test**.


- **Free:** `assessments` + `results` only; **NO** `exercises` / `plans`
- **Basic:** `assessments(3)` + `results` + `exercises` + `plans(lite)`
- **Pro:** `assessments(7)` + `results(extended)` + `exercises` + `plans`
- **Pro+:** `assessments(15)` + `results(full + poseAccuracy)` + `exercises` + `plans`


## 4.3. Assessment Tests Catalog (15) ‚Äî Elite (canonical)

**Source of truth:** the following 15 tests list (Elite). This replaces any previous 15-tests catalog.

### 4.3.1. Canonical catalog (Pro+ = 15/15)

**Hard requirement (must):** **All 15 tests must be executed and scored via MediaPipe** (no ‚Äúmanual self‚Äëreport scoring‚Äù and no non‚ÄëMediaPipe CV pipeline).

**Allowed MediaPipe modules (MVP):**
- **MediaPipe Pose** (primary) for full‚Äëbody landmarks
- **MediaPipe Face Mesh** (only if needed for neck/chin precision)

**Quality gates (must):** a test result can be finalized only if:
- Pose/Face tracking confidence is above threshold for the required landmarks for **‚â• 80%** of frames
- Camera framing is correct (full body or upper body as required)
- Lighting/occlusion checks pass (no missing hips/shoulders for body tests)

**If quality gate fails (must):**
- Do **not** mark the test as completed.
- Show user an actionable instruction screen (reposition, distance, lighting) and allow retry.
- Store an audit event: `assessment.measurement_failed` with reason (low_confidence / occlusion / out_of_frame).

**MediaPipe output normalization (must):** even when exact cm/deg is unreliable, the system must output the normalized bucket + confidence.

**Landmark/metric mapping (MVP, minimum):**
- Neck Flexion/Extension (1) + Chin Tuck (13): Face Mesh + Pose (ears/nose/shoulders) to estimate head pitch and head‚Äëneck translation.
- Plank Endurance (2), Dead Bug (11), Bird Dog (14): Pose angles + trunk alignment + stability over time.
- Clamshell (15), Glute Bridge (12): hip/knee/ankle landmarks + pelvis alignment to score ROM/control.


| ID | Test | Primary signal (MediaPipe) | Output (normalized) | Notes |
|---:|---|---|---|---|
| 1 | Neck Flexion/Extension | cervical ROM | pass / limited / significant + confidence | front/side camera options |
| 2 | Plank Endurance | time under correct alignment | seconds + pass/fail thresholds | form quality gating |
| 3 | Y-Balance | dynamic reach symmetry | symmetric / asymmetric + severity | side-to-side delta |
| 4 | Overhead Squat | knee valgus, heel lift, trunk angle, depth | good / compensation / significant + flags | key global pattern |
| 5 | 90-90 Hip/Shoulder | hip IR/ER + shoulder ER/IR proxy | within-range / limited + side | combined test (one ID) |
| 6 | Ankle Mobility | dorsiflexion ROM | pass / limited / significant + confidence | **see comparison below** |
| 7 | Single-Leg Balance | static balance stability | seconds + quality score | eyes open (MVP) |
| 8 | Lateral Lunge | frontal-plane control + hip mobility | good / compensation / significant + side | knee tracking flags |
| 9 | Shoulder Flexion | overhead ROM | pass / limited + side | scap compensation flag |
| 10 | Wall Slide | scapular control + thoracic mobility | pass / needs-work | quality score |
| 11 | Dead Bug | core stability under limb motion | pass / needs-work | lumbar control |
| 12 | Glute Bridge | posterior chain + pelvic control | pass / needs-work + side | asymmetry flag |
| 13 | Chin Tuck | deep neck flexor control | pass / needs-work | posture cue |
| 14 | Bird Dog | cross-body core + stability | pass / needs-work + side | balance drift |
| 15 | Clamshell | hip abductor activation/control | pass / needs-work + side | glute med proxy |

### 4.3.2. Tier subsets (must be fixed and consistent)

- **Free (3 tests):** 4 (Overhead Squat), 3 (Y-Balance), 7 (Single-Leg Balance)
- **Basic (3 tests):** same as Free (4, 3, 7) + unlocks exercises/plan (lite)
- **Pro (7 tests):** 4 (Overhead Squat), 3 (Y-Balance), 7 (Single-Leg Balance), 6 (Ankle Mobility), 9 (Shoulder Flexion), 2 (Plank Endurance), 11 (Dead Bug)
- **Pro+ (15 tests):** 1‚Äì15

### 4.3.3. Interpretation ‚Üí ‚Äúproblem areas‚Äù + priorities (P1/P2)

- **P1 (root cause candidates):** ankle mobility (6), hip control/activation (12/15), core control (11/14/2), shoulder/scap control (9/10)
- **P2 (often consequence patterns):** compensations in overhead squat (4), lateral lunge (8), balance asymmetries (3/7)

**Example rule (non-exhaustive):**
- If knee valgus in **Overhead Squat (4)** AND **Ankle Mobility (6)** is limited AND **Clamshell (15)** shows poor control ‚Üí priorities: P1=ankle, P1=hip abduction control; knee valgus = P2 consequence.

### 4.3.4. Ankle Mobility ‚Äî —Å—Ä–∞–≤–Ω–∏—Ç—å —Ç–µ—Å—Ç—ã (decision)

**Decision for MVP:** use **knee-to-wall** (dorsiflexion) protocol as the canonical implementation for Test 6.

- **Why:** robust, simple, maps well to video-based estimation, and directly correlates with squat/lunge mechanics.
- **Normalization:** output remains **pass / limited / significant** + confidence.
- **Optional metric:** if reliable, system may also output estimated cm-equivalent, but must not block results.

### 4.3.5. Retesting cadence + progress thresholds

- **Every 2 weeks:** quick re-check for key limitations
- **Every 4‚Äì6 weeks:** full reassessment

**Progress heuristic (MVP):**
- **‚â•20%** improvement in 2 weeks ‚Üí good
- **<10%** improvement in 2 weeks ‚Üí adjust program
- worsening ‚Üí stop / advise specialist

### 4.3.6. Report template (Pro/Pro+)

System must support generation of a structured report containing:
- identified limitations grouped by P1/P2
- recommended plan phases (2 weeks local work ‚Üí 2 weeks integration)
- progress tracking table per key tests

### 4.3.7. –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤–∏–¥–µ–æ –≤ MediaPipe (Client validation + Lambda retry)

**Goal:** –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å, —á—Ç–æ —Ç–µ—Å—Ç—ã –Ω–∞ –≤—Å–µ—Ö —Ç–∞—Ä–∏—Ñ–∞—Ö –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ MediaPipe –¥–∞–∂–µ –ø—Ä–∏ –ø–ª–æ—Ö–æ–º –≤–∏–¥–µ–æ.

#### 4.3.7.1. Client-side –≤–∞–ª–∏–¥–∞—Ü–∏—è (React, –¥–æ –æ—Ç–ø—Ä–∞–≤–∫–∏)

- **Max duration:** 45s
- **Max size:** 50MB
- **No motion check:** motion variance < threshold

```javascript
// packages/frontend/src/components/TestRecorder.jsx
const validateVideo = async (videoBlob) => {
  const issues = [];

  // Duration > 45s (obtained from <video> metadata)
  if (videoBlob.duration > 45) issues.push('TOO_LONG');

  // Size > 50MB
  if (videoBlob.size > 50 * 1024 * 1024) issues.push('TOO_LARGE');

  // No motion (variance < threshold)
  const motionScore = await analyzeMotion(videoBlob);
  if (motionScore < 0.1) issues.push('NO_MOTION');

  return issues;
};

// UI: toast with reasons + retry
const issues = await validateVideo(videoBlob);
if (issues.length) {
  toast.error(`Please re-record: ${issues.join(', ')}`);
  return;
}
```

#### 4.3.7.2. Lambda MediaPipe –æ–±—Ä–∞–±–æ—Ç–∫–∞ (Event-Driven)

**Pipeline (MVP):**
1. S3 upload ‚Üí EventBridge ‚Üí `test-engine` Lambda
2. Pre-process: crop/resize/normalize (**45s max**)
3. MediaPipe Pose (and Face Mesh if required): ~450 frames √ó 33 keypoints (Pose)
4. Apply quality gates

**Quality gates (minimum 5 checks):**

| Check | Criterion | Action |
|---|---|---|
| No keypoints | <10% frames with pose | `status = INVALID_NO_PERSON` |
| Low confidence | avg confidence < 0.5 | `status = LOW_CONFIDENCE` |
| No motion | variance keypoints < 0.05 | `status = NO_MOTION` |
| Bad lighting | brightness < 30 OR > 250 | `status = BAD_LIGHTING` |
| Wrong angle | shoulders/hips angle > 45¬∞ | `status = WRONG_ANGLE` |

#### 4.3.7.3. Retry –ª–æ–≥–∏–∫–∞ (SQS FIFO, max 3 attempts/test/day)

```javascript
// packages/backend/src/handlers/test-engine.js
export async function processVideo(event) {
  const { videoUrl, attempt = 1, userId, testId } = event;

  try {
    const keypoints = await mediapipeAnalyze(videoUrl);
    const quality = assessQuality(keypoints);

    if (!quality.valid && attempt < 3) {
      await sqs.send({
        QueueUrl: PROCESS_QUEUE,
        MessageBody: JSON.stringify({
          ...event,
          attempt: attempt + 1,
          feedback: quality.feedback
        })
      });
      return { status: 'RETRYING', feedback: quality.feedback };
    }

    if (!quality.valid) {
      // max retries reached
      await saveAssessmentFailure(userId, testId, quality);
      return { status: 'INVALID', feedback: quality.feedback };
    }

    // ‚úÖ Valid ‚Üí DynamoDB + results
    await saveAssessment(userId, testId, keypoints);
    return { status: 'SUCCESS', scores: quality.scores };

  } catch (error) {
    await dlq.send({ videoUrl, error: error.message });
    return { status: 'FAILED', error };
  }
}
```

#### 4.3.7.4. UX (Results page)

- ‚úÖ **VALID** ‚Üí –ø–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∏ –ø–ª–∞–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è Basic+)
- ‚ùå **INVALID** ‚Üí modal ‚ÄúVideo is invalid‚Äù + **specific reason** + 1‚Äëclick ‚ÄúRe-record‚Äù
- **Retry count:** –º–∞–∫—Å–∏–º—É–º 3
- **Important:** fallback questionnaire (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è) **–Ω–µ –∑–∞—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–µ—Å—Ç** –∏ –Ω–µ –∑–∞–º–µ–Ω—è–µ—Ç MediaPipe-–æ—Ü–µ–Ω–∫—É; —ç—Ç–æ —Ç–æ–ª—å–∫–æ –æ–±—â–∏–π —Å–æ–≤–µ—Ç/—Ç—Ä–∏–∞–∂.

#### 4.3.7.5. –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (DynamoDB)

| Field | Value | Action |
|---|---|---|
| `qualityScore` | 0.0‚Äì1.0 | <0.3 = invalid |
| `confidenceAvg` | 0.0‚Äì1.0 | <0.5 = retry |
| `motionVariance` | 0.0‚Äì1.0 | <0.1 = no motion |
| `status` | VALID / INVALID / RETRYING | workflow trigger |
| `feedback` | string | UX hint |

**TCO impact (example):** 20% retry ‚Üí +~20% Lambda usage; mitigate with strong client-side validation.



### 4.3.8. –ó–∞—â–∏—Ç–∞ MediaPipe –ø–∞–π–ø–∞ –æ—Ç –∞–±—å—é–∑–∞ (100+ –≤–∏–¥–µ–æ/–¥–µ–Ω—å)

**Threat model:** 1 –∞–∫–∫–∞—É–Ω—Ç –ø—ã—Ç–∞–µ—Ç—Å—è –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å **100+ –≤–∏–¥–µ–æ/–¥–µ–Ω—å** –≤–º–µ—Å—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –æ–±—ä—ë–º–∞ ‚Üí —Ä–µ–∑–∫–∏–π —Ä–æ—Å—Ç Lambda cost –∏ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞.

**Principle (must):** tier –º–µ–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ **–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤**, –Ω–æ **–ª—é–±–æ–π –≤–∏–¥–µ–æ‚Äë—Å–∞–±–º–∏—Ç** –æ–±—è–∑–∞–Ω –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —á–µ—Ä–µ–∑ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ security/quality gates –∏ quota enforcement.

#### 4.3.8.1. Client-side –ª–∏–º–∏—Ç—ã (React, –¥–æ S3)

```javascript
// packages/frontend/src/lib/videoLimiter.js
const VIDEO_LIMITS = {
  perTest: 3,      // max 3 attempts / test/day
  // Plan-aware daily quota (previous PRD)
  // Free/Basic: 9 videos/day (3√ó3)
  // Pro:        21 videos/day (7√ó3)
  // Pro+:      45 videos/day (15√ó3)
  perDayMin: 9,      // Free/Basic: 9 videos/day (3 tests √ó 3 attempts)
  perHour: 5       // baseline, server is the source of truth
};

export const canRecord = async (testId) => {
  const { data } = await api.get('/limits/status');

  if (data.banned) {
    toast.error(`Video submissions temporarily blocked: ${data.banReason}`);
    return false;
  }

  if (data.perDayRemaining <= 0) {
    toast.error('Daily video limit reached. Please continue tomorrow.');
    return false;
  }

  if (data.perTestRemaining[testId] <= 0) {
    toast.error('Max attempts for this test reached.');
    return false;
  }

  return true;
};
```

**Note:** client-side limits are UX only; **server-side enforcement is mandatory**.

#### 4.3.8.2. API Gateway + WAF (Tier 1 defense)

| Level | Limit | Action | Alarm |
|---|---:|---|---|
| Per User | 5 videos/hour (baseline) | HTTP 429 | P1: `videoSubmissions > 5/hour` |
| Per IP | 20 videos/hour | WAF block 1h | P0: `IP abuse detected` |
| Per Test | 3 attempts/test | HTTP 400 | - |
| Global | 1000 videos/hour | API GW throttle | P0: `429 rate > 5%` |

**Terraform example (if using API keys):**

```hcl
resource "aws_api_gateway_usage_plan" "video_plan" {
  name = "video-submissions"

  api_stages {
    api_id = aws_api_gateway_rest_api.main.id
    stage  = "prod"
  }

  quota_settings {
    # daily videos per user (plan-aware is enforced in backend)
    limit   = 10
    period  = "DAY"
  }

  throttle_settings {
    rate_limit  = 5
    burst_limit = 10
  }
}
```

**Implementation note (Flow Logic):** –µ—Å–ª–∏ API keys –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è (Cognito JWT), —Ç–æ per-user quota must be enforced –≤ Lambda authorizer / middleware (DynamoDB token bucket).

#### 4.3.8.3. Lambda Reserved Concurrency (Tier 2 defense)

- `test-engine` Lambda: `reservedConcurrency = 10`
- –ê–±—å—é–∑–µ—Ä –Ω–µ –º–æ–∂–µ—Ç ‚Äú—Å—ä–µ—Å—Ç—å‚Äù –≤–µ—Å—å compute.

```javascript
// CDK: packages/infra/lib/compute-stack.ts
new lambda.Function(this, 'TestEngine', {
  reservedConcurrentExecutions: 10,
  memorySize: 512,
  timeout: Duration.seconds(30)
});
```

#### 4.3.8.4. SQS FIFO + Circuit Breaker (Tier 3 defense)

- –í–∏–¥–µ–æ ‚Üí SQS FIFO
- **Deduplication** –ø–æ `userId + testId + attempt` (–∏–ª–∏ hash video)
- Consumer enforces **max 3 messages/test** and **plan-aware daily quota**.
- –ü—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ ‚Üí DLQ + ban.

```javascript
// packages/backend/src/handlers/video-queue.js
export async function processVideoQueue(event) {
  const messages = event.Records;

  const userVideos = groupBy(messages, 'userId');

  for (const [userId, videos] of Object.entries(userVideos)) {
    // Tier 3 guard: per-batch abuse
    if (videos.length > 3) {
      await banUser(userId, 'VIDEO_ABUSE', 24*60*60);
      continue;
    }

    // normal MediaPipe processing...
  }
}
```

**Circuit breaker (must):**
- if `429 rate > 5%` OR `Lambda cost spike > $10/hour` ‚Üí emergency throttle video submission endpoints (and alert on-call).

#### 4.3.8.5. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π ban (Tier 4)

**Important:** ban never ‚Äúswitches‚Äù test scoring to non‚ÄëMediaPipe. It only blocks submissions.

| Abuse | Action | Duration |
|---|---|---|
| `> perDayQuota(plan)` | Soft ban: block video submissions | 24h |
| `> 50/day` (clearly abusive; violates monthly rule) | Hard ban: block account features | 7 days |
| `> 100/day` (clearly abusive; violates monthly rule) | Permanent ban + report | forever |

#### 4.3.8.6. DynamoDB `userLimits` (source of truth)

Minimal schema (example):

```
userId: "abc123"
plan: "proplus"
videoQuotaUsedDaily: 105
videoQuotaDay: 45  // Pro+: 15 tests √ó 3 attempts
videoQuotaUsedHourly: 6
banUntil: "2025-12-18T23:59Z"
banReason: "VIDEO_ABUSE"
updatedAt: "..."
```

#### 4.3.8.7. Monitoring + Alerting

| Metric | Threshold | Action |
|---|---|---|
| `videoSubmissions/user > perDayQuota(plan)` | P0 | auto-ban + Slack |
| `429 errors > 5%` | P1 | tighten WAF / throttle |
| `Lambda cost spike > $10/hour` | P0 | emergency throttle |

#### 4.3.8.8. TCO impact (example)

- Without protection: 1% abusers √ó 100 videos/day ‚Üí high cost.
- With protection: enforce plan-aware daily quota + reserved concurrency + WAF ‚Üí **-90%** abuse cost.

---

# 5. CI/CD STRATEGY

## 5.1. Repository Structure (Monorepo)

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** Turborepo.

```
musclebalance/
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ frontend/          # Flow Logic React app
‚îÇ   ‚îú‚îÄ‚îÄ backend/           # Lambda handlers (API)
‚îÇ   ‚îú‚îÄ‚îÄ shared/            # Shared types/schemas
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/    # Terraform/IaC
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ turbo.json
```

## 5.2. Environment Strategy

| Environment | Branch | Auto-deploy | URL | Purpose |
|-------------|--------|-------------|-----|---------|
| Development | feature/* | ‚ùå | localhost:3000 | Local dev |
| Preview | PR | ‚úÖ | pr-*.vercel.app | Code review |
| Staging | develop | ‚úÖ | staging.flowlogic.app | QA |
| Production | main | ‚ö†Ô∏è Manual approval | flowlogic.app | Live users |

## 5.3. CI/CD Pipeline

```yaml
# .github/workflows/deploy.yml
name: Deploy Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  AWS_REGION: us-east-1
  NODE_VERSION: '20'

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      - name: Install dependencies
        run: npm ci
      - name: Lint
        run: npm run lint
      - name: Type check
        run: npm run type-check
      - name: Unit tests
        run: npm run test:unit
      - name: Integration tests
        run: npm run test:integration

  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Dependency vulnerability scan
        run: npm audit --production
      - name: SAST (Static Analysis)
        uses: github/codeql-action/analyze@v2
      - name: Secret scanning
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./

  build:
    needs: [validate, security-scan]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install dependencies
        run: npm ci
      - name: Build frontend
        run: npm run build --workspace=frontend
      - name: Build backend
        run: npm run build --workspace=backend
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            packages/frontend/dist
            packages/backend/.serverless

  deploy-staging:
    needs: build
    if: github.ref == 'refs/heads/develop'
    runs-on: ubuntu-latest
    environment: staging
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: build-artifacts
      - name: Deploy frontend to Vercel
        run: vercel deploy --prebuilt
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
          VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}
      - name: Deploy backend (Serverless)
        run: |
          cd packages/backend
          serverless deploy --stage staging
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      - name: Run smoke tests
        run: npm run test:smoke -- --env=staging

  deploy-production:
    needs: build
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://flowlogic.app
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: build-artifacts
      - name: Deploy frontend
        run: vercel deploy --prod
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
      - name: Deploy backend
        run: |
          cd packages/backend
          serverless deploy --stage production
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      - name: Run migrations
        run: npm run migrate:up
        env:
          AWS_REGION: us-east-1
          STAGE: production
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      - name: Run smoke tests
        run: npm run test:smoke -- --env=production
        timeout-minutes: 5
      - name: Rollback on failure
        if: failure()
        run: |
          echo "Deployment failed, rolling back..."
          vercel rollback --token=${{ secrets.VERCEL_TOKEN }}
          cd packages/backend
          serverless rollback --stage production
```

## 5.4. Performance Targets

- Build time: ~3‚Äì4 min (cache)
- Deploy time: FE ~30s, BE ~2‚Äì3 min
- Rollback time: < 1 min

---

# 6. DEPLOYMENT ROLLBACK POLICY

## 6.1. Automatic Rollback Triggers

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π rollback –ø—Ä–∏:
- Smoke tests fail (timeout 5 min)
- Error rate > 5 –æ—à–∏–±–æ–∫ –∑–∞ 5 –º–∏–Ω—É—Ç
- `/health` = unhealthy
- Sentry critical alerts

## 6.2. Manual Rollback Procedures

```bash
#!/bin/bash
# scripts/rollback.sh

STAGE=$1
VERSION=$2

if [ -z "$STAGE" ] || [ -z "$VERSION" ]; then
  echo "Usage: ./rollback.sh <stage> <version>"
  echo "Example: ./rollback.sh production v1.2.3"
  exit 1
fi

echo "Rolling back $STAGE to version $VERSION"

# Rollback frontend (Vercel)
vercel rollback --token=$VERCEL_TOKEN

# Rollback backend (Serverless)
cd packages/backend
serverless deploy --stage $STAGE --package .serverless-$VERSION

# Verify health
HEALTH_CHECK=$(curl -s https://api.flowlogic.app/health | jq -r '.status')
if [ "$HEALTH_CHECK" != "healthy" ]; then
  echo "Rollback verification failed"
  exit 1
fi

echo "Rollback complete and verified"
```

## 6.3. Health Check Endpoint

```javascript
// packages/backend/src/handlers/health.js
export const handler = async () => {
  const checks = {
    database: await checkDynamoDB(),
    s3: await checkS3(),
    cognito: await checkCognito(),
    eventbridge: await checkEventBridge()
  };

  const allHealthy = Object.values(checks).every(c => c.status === 'ok');

  return {
    statusCode: allHealthy ? 200 : 503,
    body: JSON.stringify({
      status: allHealthy ? 'healthy' : 'unhealthy',
      timestamp: new Date().toISOString(),
      version: process.env.VERSION,
      environment: process.env.STAGE,
      checks
    })
  };
};
```

## 6.4. Rollback Testing

- Frequency: monthly
- Procedure: deploy staging ‚Üí rollback ‚Üí verify `/health` + –∫–ª—é—á–µ–≤—ã–µ —Ñ–ª–æ—É ‚Üí document

---

# 7. ENVIRONMENT VARIABLES MANAGEMENT

## 7.1. Environment Variables Structure

```bash
# .env.example

AWS_REGION=us-east-1
STAGE=local

# Cognito
COGNITO_USER_POOL_ID=us-east-1_xxxxx
COGNITO_CLIENT_ID=xxxxx

# DynamoDB
DYNAMODB_USERS_TABLE=flowlogic-${STAGE}-users
DYNAMODB_SUBSCRIPTIONS_TABLE=flowlogic-${STAGE}-subscriptions
DYNAMODB_ASSESSMENTS_TABLE=flowlogic-${STAGE}-assessments
DYNAMODB_PLANS_TABLE=flowlogic-${STAGE}-plans
DYNAMODB_EXERCISES_TABLE=flowlogic-${STAGE}-exercises

# S3/CDN
S3_VIDEOS_BUCKET=flowlogic-${STAGE}-videos

# Stripe
STRIPE_SECRET_KEY=sk_test_xxxxx
STRIPE_WEBHOOK_SECRET=whsec_xxxxx

# Sentry
SENTRY_DSN=https://xxxxx@sentry.io/xxxxx

# API
API_BASE_URL=https://api.flowlogic.app
```

## 7.2. Secrets Management Strategy

- GitHub Secrets: deploy keys/tokens
- AWS Secrets Manager: runtime secrets

```javascript
// packages/backend/src/config/secrets.js
import { SecretsManager } from '@aws-sdk/client-secrets-manager';

const client = new SecretsManager({ region: process.env.AWS_REGION });
let cachedSecrets = null;

export async function getSecrets() {
  if (cachedSecrets) return cachedSecrets;
  const response = await client.getSecretValue({
    SecretId: `flowlogic/${process.env.STAGE}/secrets`
  });
  cachedSecrets = JSON.parse(response.SecretString);
  return cachedSecrets;
}
```

## 7.3. Environment-specific Configuration

| Variable | Development | Staging | Production |
|----------|-------------|---------|------------|
| AWS_REGION | us-east-1 | us-east-1 | us-east-1 |
| LOG_LEVEL | debug | info | error |
| CACHE_TTL | 60s | 300s | 3600s |
| RATE_LIMIT | 1000/min | 100/min | 50/min |

---

# 8. LOCAL DEVELOPMENT SETUP

## 8.1. Docker Compose Environment

```yaml
# docker-compose.yml
version: '3.8'
services:
  dynamodb-local:
    image: amazon/dynamodb-local:latest
    ports: ["8000:8000"]
    command: "-jar DynamoDBLocal.jar -sharedDb -dbPath ./data"
  dynamodb-admin:
    image: aaronshaf/dynamodb-admin:latest
    ports: ["8001:8001"]
    environment:
      DYNAMO_ENDPOINT: http://dynamodb-local:8000
    depends_on: [dynamodb-local]
  localstack:
    image: localstack/localstack:latest
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3,sqs,lambda,secretsmanager,eventbridge
      - DEBUG=1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
```

## 8.2. Development Scripts

```json
{
  "scripts": {
    "dev": "concurrently \"npm:dev:*\"",
    "dev:services": "docker-compose up -d",
    "dev:frontend": "cd packages/frontend && vite",
    "dev:backend": "cd packages/backend && serverless offline --stage local",
    "setup:local": "node scripts/setup-local-tables.js",
    "seed:local": "node scripts/seed-local-data.js",
    "test:smoke": "node scripts/smoke.js"
  }
}
```

---

# 9. DATABASE MIGRATION STRATEGY

## 9.1. Migration Framework

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–∏–≥—Ä–∞—Ü–∏–π

```
packages/backend/migrations/
‚îú‚îÄ‚îÄ 001_create_users_table.js
‚îú‚îÄ‚îÄ 002_create_subscriptions_table.js
‚îú‚îÄ‚îÄ 003_create_assessments_table.js
‚îú‚îÄ‚îÄ 004_create_plans_table.js
‚îî‚îÄ‚îÄ migrate.js
```

### Migration Template

```javascript
// packages/backend/migrations/001_create_users_table.js
export const up = async (dynamodb) => {
  console.log('Running migration: 001_create_users_table');

  const params = {
    TableName: `flowlogic-${process.env.STAGE}-users`,
    KeySchema: [
      { AttributeName: 'user_id', KeyType: 'HASH' }
    ],
    AttributeDefinitions: [
      { AttributeName: 'user_id', AttributeType: 'S' },
      { AttributeName: 'email', AttributeType: 'S' }
    ],
    GlobalSecondaryIndexes: [
      {
        IndexName: 'email-index',
        KeySchema: [
          { AttributeName: 'email', KeyType: 'HASH' }
        ],
        Projection: { ProjectionType: 'ALL' }
      }
    ],
    BillingMode: 'PAY_PER_REQUEST',
    StreamSpecification: {
      StreamEnabled: true,
      StreamViewType: 'NEW_AND_OLD_IMAGES'
    },
    SSESpecification: {
      Enabled: true,
      SSEType: 'KMS',
      KMSMasterKeyId: process.env.KMS_KEY_ID
    }
  };

  try {
    await dynamodb.createTable(params).promise();
    console.log('‚úÖ Table created successfully');
  } catch (error) {
    if (error.code === 'ResourceInUseException') {
      console.log('‚ö†Ô∏è Table already exists, skipping');
    } else {
      throw error;
    }
  }
};

export const down = async (dynamodb) => {
  console.log('Rolling back migration: 001_create_users_table');

  try {
    await dynamodb.deleteTable({
      TableName: `flowlogic-${process.env.STAGE}-users`
    }).promise();
    console.log('‚úÖ Table deleted successfully');
  } catch (error) {
    if (error.code === 'ResourceNotFoundException') {
      console.log('‚ö†Ô∏è Table does not exist, skipping');
    } else {
      throw error;
    }
  }
};

export const metadata = {
  version: '001',
  description: 'Create users table with email GSI',
  author: 'team@flowlogic.app',
  createdAt: '2025-12-18'
};
```

## 9.2. Migration Runner

```javascript
// packages/backend/migrations/migrate.js
import AWS from 'aws-sdk';
import fs from 'fs';
import path from 'path';

const dynamodb = new AWS.DynamoDB({
  region: process.env.AWS_REGION || 'us-east-1'
});

const MIGRATIONS_TABLE = `flowlogic-${process.env.STAGE}-migrations`;

async function ensureMigrationsTable() {
  try {
    await dynamodb.describeTable({ TableName: MIGRATIONS_TABLE }).promise();
  } catch (error) {
    if (error.code === 'ResourceNotFoundException') {
      await dynamodb.createTable({
        TableName: MIGRATIONS_TABLE,
        KeySchema: [{ AttributeName: 'version', KeyType: 'HASH' }],
        AttributeDefinitions: [{ AttributeName: 'version', AttributeType: 'S' }],
        BillingMode: 'PAY_PER_REQUEST'
      }).promise();

      console.log('‚úÖ Migrations table created');
    } else {
      throw error;
    }
  }
}

async function getAppliedMigrations() {
  const result = await dynamodb.scan({ TableName: MIGRATIONS_TABLE }).promise();
  return (result.Items || []).map(item => item.version.S);
}

async function recordMigration(version, metadata) {
  await dynamodb.putItem({
    TableName: MIGRATIONS_TABLE,
    Item: {
      version: { S: version },
      appliedAt: { S: new Date().toISOString() },
      description: { S: metadata.description },
      author: { S: metadata.author }
    }
  }).promise();
}

async function loadMigrations() {
  const migrationsDir = path.join(__dirname);
  const files = fs.readdirSync(migrationsDir)
    .filter(f => f.match(/^\d{3}_.*\.js$/) && f !== 'migrate.js')
    .sort();

  const migrations = [];
  for (const file of files) {
    const migration = await import(`./${file}`);
    migrations.push({
      file,
      version: migration.metadata.version,
      up: migration.up,
      down: migration.down,
      metadata: migration.metadata
    });
  }

  return migrations;
}

async function migrateUp() {
  console.log('üöÄ Running database migrations...');

  await ensureMigrationsTable();

  const applied = await getAppliedMigrations();
  const all = await loadMigrations();

  const pending = all.filter(m => !applied.includes(m.version));

  if (pending.length === 0) {
    console.log('‚ú® No pending migrations');
    return;
  }

  for (const migration of pending) {
    console.log(`Applying: ${migration.version} - ${migration.metadata.description}`);
    await migration.up(dynamodb);
    await recordMigration(migration.version, migration.metadata);
    console.log(`‚úÖ Applied: ${migration.version}`);
  }

  console.log('‚ú® All migrations applied successfully');
}

const command = process.argv[2];

if (command === 'up') {
  migrateUp().catch(error => {
    console.error('Migration failed:', error);
    process.exit(1);
  });
} else {
  console.log('Usage: npm run migrate:up');
  process.exit(1);
}
```

## 9.3. Migration Scripts in package.json

```json
{
  "scripts": {
    "migrate:up": "node packages/backend/migrations/migrate.js up"
  }
}
```

## 9.4. Migration in CI/CD

```yaml
# –í deploy pipeline –ø–æ—Å–ª–µ deploy backend –∏ –¥–æ smoke tests
- name: Run migrations
  run: npm run migrate:up
  env:
    AWS_REGION: us-east-1
    STAGE: ${{ github.event.inputs.environment }}
    AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
    AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
```

---

# 10. SECURITY REQUIREMENTS

## 10.1. Security Scanning in CI/CD (–ø–æ–ª–Ω—ã–π workflow)

```yaml
# .github/workflows/security.yml
name: Security Scanning

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 0 * * 0'   # weekly

jobs:
  sast:
    name: SAST (CodeQL)
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
    steps:
      - uses: actions/checkout@v4
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: javascript, typescript
      - name: Autobuild
        uses: github/codeql-action/autobuild@v3
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3

  dependency-scan:
    name: Dependency Vulnerabilities
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      - name: Install dependencies
        run: npm ci
      - name: npm audit
        run: npm audit --production --audit-level=moderate
        continue-on-error: true

  secret-scan:
    name: Secret Scanning
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: TruffleHog
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: ${{ github.event.repository.default_branch }}
          head: HEAD
          extra_args: --debug --only-verified
      - name: Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  iac-scan:
    name: IaC Security (tfsec/checkov)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: tfsec
        uses: aquasecurity/tfsec-action@v1.0.3
        with:
          soft_fail: true
      - name: checkov
        uses: bridgecrewio/checkov-action@master
        with:
          directory: packages/infrastructure/
          framework: terraform
          quiet: true

  container-scan:
    name: Container Security (Trivy)
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    permissions:
      actions: read
      contents: read
      security-events: write
    steps:
      - uses: actions/checkout@v4
      - name: Build Docker image
        run: docker build -t flowlogic:test .
      - name: Run Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: flowlogic:test
          format: 'sarif'
          output: 'trivy-results.sarif'
      - name: Upload SARIF
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'
```

## 10.2. Security Hardening Checklist (MVP)

### Application Security

- Authentication:
  - AWS Cognito
  - JWT access token TTL 15 min
  - Refresh token storage (httpOnly cookie)
- Authorization:
  - Tier-gating enforcement on backend (Free cannot access plans/exercises)
  - IAM least privilege
- Data protection:
  - KMS encryption for PII at rest
  - TLS 1.3 in transit
  - No PII in logs (masking)
- Input validation:
  - Schema validation
  - Rate limiting

### Secrets Management

- No secrets in repo
- GitHub Secrets for CI/CD
- AWS Secrets Manager for runtime

## 10.3. Security Response Plan

- Phase 1: Detection (0‚Äì15 min)
- Phase 2: Assessment (15‚Äì30 min)
- Phase 3: Containment (30‚Äì60 min)
- Phase 4: Eradication (1‚Äì4 h)
- Phase 5: Recovery (4‚Äì24 h)
- Phase 6: Post‚ÄëMortem (1‚Äì3 d)

---

# 11. MONITORING & ALERTING

## 11.1. CloudWatch Alarms Configuration

### 11.1.1. Critical Alarms (P0)

```hcl
# infrastructure/terraform/monitoring.tf

# Lambda Critical Errors
resource "aws_cloudwatch_metric_alarm" "lambda_critical_errors" {
  alarm_name          = "flowlogic-${var.environment}-lambda-critical-errors"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "1"
  metric_name         = "Errors"
  namespace           = "AWS/Lambda"
  period              = "60"
  statistic           = "Sum"
  threshold           = "10"
  alarm_description   = "P0: Lambda error rate > 10/min"
  treat_missing_data  = "notBreaching"

  alarm_actions = [
    aws_sns_topic.slack_critical.arn
  ]

  dimensions = {
    FunctionName = "flowlogic-${var.environment}-api"
  }
}

# API Gateway 5xx Errors
resource "aws_cloudwatch_metric_alarm" "api_5xx_errors" {
  alarm_name          = "flowlogic-${var.environment}-api-5xx"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "5XXError"
  namespace           = "AWS/ApiGateway"
  period              = "300"
  statistic           = "Sum"
  threshold           = "20"
  alarm_description   = "P0: API 5xx errors > 20 in 5 min"

  alarm_actions = [aws_sns_topic.slack_critical.arn]
}

# DynamoDB Throttling
resource "aws_cloudwatch_metric_alarm" "dynamodb_throttles" {
  alarm_name          = "flowlogic-${var.environment}-dynamodb-throttles"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "1"
  metric_name         = "UserErrors"
  namespace           = "AWS/DynamoDB"
  period              = "300"
  statistic           = "Sum"
  threshold           = "5"
  alarm_description   = "P0: DynamoDB throttling detected"

  alarm_actions = [aws_sns_topic.slack_critical.arn]

  dimensions = {
    TableName = "flowlogic-${var.environment}-users"
  }
}

# Payment Processing Failures (custom metric)
resource "aws_cloudwatch_metric_alarm" "payment_failures" {
  alarm_name          = "flowlogic-${var.environment}-payment-failures"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "1"
  metric_name         = "PaymentFailed"
  namespace           = "FlowLogic"
  period              = "300"
  statistic           = "Sum"
  threshold           = "5"
  alarm_description   = "P0: Payment failures > 5 in 5 min"

  alarm_actions = [aws_sns_topic.slack_critical.arn]
}
```

### 11.1.2. High Priority Alarms (P1)

```hcl
# API Latency P95
resource "aws_cloudwatch_metric_alarm" "api_latency_p95" {
  alarm_name          = "flowlogic-${var.environment}-api-latency-p95"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"

  metric_query {
    id          = "p95"
    return_data = true

    metric {
      metric_name = "Duration"
      namespace   = "AWS/Lambda"
      period      = 300
      stat        = "p95"

      dimensions = {
        FunctionName = "flowlogic-${var.environment}-api"
      }
    }
  }

  threshold         = 1000
  alarm_description = "P1: API P95 latency > 1s"

  alarm_actions = [aws_sns_topic.slack_high.arn]
}

# CloudFront cache hit rate (low)
resource "aws_cloudwatch_metric_alarm" "cloudfront_cache_hit_rate" {
  alarm_name          = "flowlogic-${var.environment}-cache-hit-rate"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CacheHitRate"
  namespace           = "AWS/CloudFront"
  period              = "3600"
  statistic           = "Average"
  threshold           = "80"
  alarm_description   = "P1: CloudFront cache hit rate < 80%"

  alarm_actions = [aws_sns_topic.slack_high.arn]
}
```

## 11.2. Custom Metrics

### 11.2.1 Business Metrics Publisher

```javascript
// packages/backend/src/utils/metrics.js
import { CloudWatch } from '@aws-sdk/client-cloudwatch';

const cloudwatch = new CloudWatch({ region: process.env.AWS_REGION || 'us-east-1' });

export class MetricsPublisher {
  constructor(namespace = 'FlowLogic') {
    this.namespace = namespace;
    this.buffer = [];
  }

  async publish(metricName, value, unit = 'Count', dimensions = {}) {
    const metric = {
      MetricName: metricName,
      Value: value,
      Unit: unit,
      Timestamp: new Date(),
      Dimensions: [
        { Name: 'Environment', Value: process.env.STAGE || 'unknown' },
        ...Object.entries(dimensions).map(([k, v]) => ({ Name: k, Value: String(v) }))
      ]
    };

    this.buffer.push(metric);

    if (this.buffer.length >= 20) {
      await this.flush();
    }
  }

  async flush() {
    if (this.buffer.length === 0) return;

    await cloudwatch.putMetricData({
      Namespace: this.namespace,
      MetricData: this.buffer
    });

    this.buffer = [];
  }
}

export const metrics = new MetricsPublisher();
```

## 11.3. Dashboard Configuration

### 11.3.1 Operational Dashboard

```json
{
  "widgets": [
    {
      "type": "metric",
      "properties": {
        "title": "API Performance",
        "metrics": [
          ["AWS/Lambda", "Invocations", { "stat": "Sum" }],
          [".", "Errors", { "stat": "Sum", "color": "#d62728" }],
          [".", "Duration", { "stat": "p95", "label": "P95 Latency" }]
        ],
        "period": 300,
        "region": "us-east-1"
      }
    },
    {
      "type": "metric",
      "properties": {
        "title": "Business Metrics",
        "metrics": [
          ["FlowLogic", "UserRegistration", { "stat": "Sum" }],
          [".", "TestCompleted", { "stat": "Sum" }],
          [".", "PaymentSuccess", { "stat": "Sum" }],
          [".", "PlanGenerated", { "stat": "Sum" }]
        ],
        "period": 3600,
        "region": "us-east-1"
      }
    }
  ]
}
```

## 11.4. Alerting Channels

### 11.4.1 SNS Topics Configuration

```hcl
# infrastructure/terraform/alerting.tf
resource "aws_sns_topic" "slack_critical" {
  name = "flowlogic-${var.environment}-slack-critical"
}

resource "aws_sns_topic" "slack_high" {
  name = "flowlogic-${var.environment}-slack-high"
}

resource "aws_sns_topic" "slack_medium" {
  name = "flowlogic-${var.environment}-slack-medium"
}
```

### 11.4.2 Slack Integration (SNS ‚Üí Lambda)

```javascript
// packages/backend/src/handlers/slack-notifier.js
export async function handler(event) {
  const message = JSON.parse(event.Records[0].Sns.Message);

  const severity = message.AlarmName.includes('critical') ? 'üî¥ CRITICAL' :
                   message.AlarmName.includes('high') ? 'üü† HIGH' :
                   'üü° MEDIUM';

  const slackMessage = {
    text: `${severity}: ${message.AlarmName}`
  };

  await fetch(process.env.SLACK_WEBHOOK_URL, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(slackMessage)
  });
}
```

---

# 12. CHANGELOG & VERSION CONTROL

## 12.1. Semantic Versioning

–ü—Ä–æ–µ–∫—Ç —Å–ª–µ–¥—É–µ—Ç Semantic Versioning 2.0.0:
- **MAJOR:** breaking changes
- **MINOR:** backward compatible features
- **PATCH:** backward compatible bug fixes

–§–æ—Ä–º–∞—Ç: **MAJOR.MINOR.PATCH** (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1.2.3)

## 12.2. Release Process

### 12.2.1. Manual steps (release branch)

```bash
# 1) create release branch
git checkout -b release/v1.2.0

# 2) bump version
npm version minor --no-git-tag-version

# 3) update CHANGELOG.md
# 4) commit
git commit -am "chore: release v1.2.0"

# 5) open PR to main
gh pr create --title "Release v1.2.0" --base main --body "$(cat CHANGELOG.md | head -80)"

# 6) merge -> CI deploys to production

# 7) merge main back to develop
git checkout develop
git merge main
git push origin develop
```

### 12.2.2. GitHub Actions Release Workflow

```yaml
# .github/workflows/release.yml
name: Release

on:
  push:
    branches:
      - main

jobs:
  release:
    if: startsWith(github.event.head_commit.message, 'chore: release v')
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: read
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Extract version
        id: version
        run: |
          VERSION=$(cat package.json | python3 -c "import json,sys; print(json.load(sys.stdin).get('version','0.0.0'))")
          echo "version=$VERSION" >> $GITHUB_OUTPUT

      - name: Create git tag
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git tag -a v${{ steps.version.outputs.version }} -m "Release v${{ steps.version.outputs.version }}"
          git push origin v${{ steps.version.outputs.version }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: v${{ steps.version.outputs.version }}
          name: Release v${{ steps.version.outputs.version }}
          generate_release_notes: true
```

## 12.3. CHANGELOG.md Structure

```markdown
# Changelog

All notable changes to this project will be documented in this file.

The format is based on Keep a Changelog,
and this project adheres to Semantic Versioning.

## [Unreleased]

### Added
- Feature in progress

## [1.2.0] - 2025-02-15

### Added
- CI/CD pipeline with automatic rollback
- Database migration framework
- Security scanning (SAST/secret scanning/IaC)
- Monitoring dashboards and alerts

### Changed
- Improved deploy performance with caching

### Fixed
- Bug fixes

### Security
- Dependency updates
```

## 12.4. Infrastructure and Database Versioning

- IaC changes are versioned with code.
- DB migrations must be backwards compatible.

## 12.5. Guaranteed Rollback Strategy

–õ—é–±–∞—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ breaking –º–∏–≥—Ä–∞—Ü–∏—è –¥–µ–ª–∞–µ—Ç—Å—è –≤ 2 —Ä–µ–ª–∏–∑–∞ (expand/contract), —á—Ç–æ–±—ã –±—ã–ª –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π rollback.

## 12.6. Hotfix Flow

1. `hotfix/v1.2.1` from `main`
2. fix + tests
3. merge into `main`
4. auto deploy
5. merge `main` back into `develop`

## 12.7. Git Best Practices

- No direct commits to `main`/`develop`
- PRs only, squash merge preferred
- Conventional Commits: `type(scope): summary`

---

# 13. LEGAL & COMPLIANCE

- Wellness only disclaimer (mandatory consent)
- GDPR/CCPA delete/export
- Accessibility: WCAG 2.1 AA (target)
- COPPA: 18+ (MVP)

